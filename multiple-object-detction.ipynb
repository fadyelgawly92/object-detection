{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install https://github.com/fastai/fastai/archive/master.zip \n!pip install fastai==0.7.0 \n!pip install torchtext==0.2.3 \n!pip install opencv-python \n!apt update && apt install -y libsm6 libxext6 \n!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n!pip3 install torchvision\n!pip install --upgrade git+https://github.com/valeoai/dl_utils.git\n!pip install --upgrade imageio\n!pip install libsixel-python\n!pip install -U pillow\n!pip install image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-25T17:27:26.245386Z","iopub.execute_input":"2022-03-25T17:27:26.246298Z","iopub.status.idle":"2022-03-25T17:29:19.116477Z","shell.execute_reply.started":"2022-03-25T17:27:26.246179Z","shell.execute_reply":"2022-03-25T17:29:19.115577Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline \n%reload_ext autoreload \n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:19.121487Z","iopub.execute_input":"2022-03-25T17:29:19.123411Z","iopub.status.idle":"2022-03-25T17:29:19.183879Z","shell.execute_reply.started":"2022-03-25T17:29:19.123374Z","shell.execute_reply":"2022-03-25T17:29:19.183211Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !pip install keras\n# !pip install h5py==3.1.0 numpy==1.19.2 six==1.15.0 typing-extensions==3.7.4 wrapt==1.12.1 botocore==1.20.106 gast==0.4.0 tensorboard==2.6 tensorflow-estimator==2.6 absl-py==0.9 protobuf==3.11.2 scikit-learn==0.24 fsspec==2021.07.0 google-api-python-client==1.12.1\n# !pip install --upgrade tensorflow\n# !pip install --ignore-installed --upgrade tensorflow-gpu==1.15.0","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:19.187926Z","iopub.execute_input":"2022-03-25T17:29:19.189818Z","iopub.status.idle":"2022-03-25T17:29:19.229264Z","shell.execute_reply.started":"2022-03-25T17:29:19.189781Z","shell.execute_reply":"2022-03-25T17:29:19.228533Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path \nimport json \nimport PIL \nfrom matplotlib import patches, patheffects\nimport keras\nfrom keras.models import Sequential, Model \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.layers import Dropout, Flatten,Dense\nfrom tensorflow.keras.optimizers import Adam\n\nimport numpy as np\nimport os\nfrom matplotlib import image,patches,patheffects\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:19.235210Z","iopub.execute_input":"2022-03-25T17:29:19.237187Z","iopub.status.idle":"2022-03-25T17:29:24.094834Z","shell.execute_reply.started":"2022-03-25T17:29:19.237148Z","shell.execute_reply":"2022-03-25T17:29:24.094014Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"PATH = Path('../input/pascalVOC/VOCdevkit/VOC2007')\nBD = json.load((PATH / 'pascal_train2007.json').open())\nIMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']\nFILE_NAME,ID,IMG_ID,CAT_ID,BBOX = 'file_name','id','image_id','category_id','bbox'\n\ndata_category = dict((o[ID], o['name']) for o in BD[CATEGORIES])\ndata_filename = dict((o[ID], o[FILE_NAME]) for o in BD[IMAGES])\ndata_ids = [o[ID] for o in BD[IMAGES]]\n\nIMG_PATH = PATH/'JPEGImages'","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:24.096328Z","iopub.execute_input":"2022-03-25T17:29:24.096589Z","iopub.status.idle":"2022-03-25T17:29:24.215155Z","shell.execute_reply.started":"2022-03-25T17:29:24.096554Z","shell.execute_reply":"2022-03-25T17:29:24.214408Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import collections\n\ndef get_annotation():\n    annotations = collections.defaultdict(lambda:[])\n    for o in BD[ANNOTATIONS]:\n        if not o['ignore']:\n            bb = o[BBOX]\n            bb = np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n            annotations[o[IMG_ID]].append((bb,o[CAT_ID]))\n    return annotations\n\ntrain_annotation = get_annotation()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:24.216418Z","iopub.execute_input":"2022-03-25T17:29:24.216652Z","iopub.status.idle":"2022-03-25T17:29:24.288287Z","shell.execute_reply.started":"2022-03-25T17:29:24.216620Z","shell.execute_reply":"2022-03-25T17:29:24.287315Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def show_img(im, figsize=None, ax=None):\n    if not ax: fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.set_xticks(np.arange(0, 224, 224/4))\n    ax.set_yticks(np.arange(0, 224, 224/4))\n    ax.grid()\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])\n    return ax\n\ndef draw_outline(o, lw):\n    o.set_path_effects([patheffects.Stroke(\n        linewidth=lw, foreground='black'), patheffects.Normal()])\n\ndef draw_rect(ax, b, color='white'):\n    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n    draw_outline(patch, 4)\n\ndef draw_text(ax, xy, txt, sz=14, color='white'):\n    text = ax.text(*xy, txt,\n        verticalalignment='top', color=color, fontsize=sz, weight='bold')\n    draw_outline(text, 1)\n    \ndef bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])  ","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:24.289451Z","iopub.execute_input":"2022-03-25T17:29:24.289714Z","iopub.status.idle":"2022-03-25T17:29:24.349802Z","shell.execute_reply.started":"2022-03-25T17:29:24.289680Z","shell.execute_reply":"2022-03-25T17:29:24.348939Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input,GlobalAveragePooling2D, Flatten,Conv2D,Concatenate\nfrom keras.activations import relu, softmax\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation\n\nsz = 224\n\nfrom keras.layers import Input,GlobalAveragePooling2D, Flatten,Conv2D,Concatenate\nfrom keras.activations import relu, softmax\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation\n\nsz = 224\n\ndef StdConv(kernel_size,stride_size,n_output):    \n    def f(input):\n        x = Conv2D(kernel_size=kernel_size, filters=n_output, strides=stride_size, padding='same')(input)\n        x = Activation(relu)(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.25)(x)   \n\n        return x\n    \n    return f\n\ndef SSD_Model():\n    net = VGG16(include_top=False, weights='imagenet', input_shape=(sz,sz,3))\n    for layer in net.layers:\n        layer.trainable=False \n        \n    x = net.output\n    x = Activation(relu)(x)\n    x = Dropout(0.25,name='VGG_backbone')(x)   \n    \n    # Output tensor shape of VGG is [7*7*512]\n\n    x = StdConv(kernel_size=3,stride_size=1,n_output=256)(x) #[7*7*256]\n    x = StdConv(kernel_size=3,stride_size=2,n_output=128)(x) #[4*4*128]\n\n    # (1) classification branch\n    nb_cat=20\n    x1 = Conv2D(kernel_size=3, filters=nb_cat, strides=1, padding='same')(x)\n    #x1 = Dropout(0.5)(x1) \n    x1 = Activation('sigmoid',name='classif')(x1)\n    \n    # (2) Box regression Branch\n    x2 = Conv2D(kernel_size=3, filters=4, strides=1, padding='same')(x)\n    x2 = Activation('linear',name='regression')(x2)\n    \n    # Then, we concatenate the 2 branch together\n    out = Concatenate()([Flatten()(x1), Flatten()(x2)])\n        \n    model = Model(inputs=net.input, outputs=out)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:24.352758Z","iopub.execute_input":"2022-03-25T17:29:24.353039Z","iopub.status.idle":"2022-03-25T17:29:24.412799Z","shell.execute_reply.started":"2022-03-25T17:29:24.353002Z","shell.execute_reply":"2022-03-25T17:29:24.411936Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"net = SSD_Model()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:24.413935Z","iopub.execute_input":"2022-03-25T17:29:24.414370Z","iopub.status.idle":"2022-03-25T17:29:27.749081Z","shell.execute_reply.started":"2022-03-25T17:29:24.414334Z","shell.execute_reply":"2022-03-25T17:29:27.748294Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"net.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:27.753871Z","iopub.execute_input":"2022-03-25T17:29:27.754138Z","iopub.status.idle":"2022-03-25T17:29:27.821848Z","shell.execute_reply.started":"2022-03-25T17:29:27.754110Z","shell.execute_reply":"2022-03-25T17:29:27.821152Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"mc = [[data_category[p[1]] for p in train_annotation[o]] for o in data_ids] # all object labels 'name' per image, list of images, each of lists of annotations, but only the classes\n\nmc[:3]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:27.826060Z","iopub.execute_input":"2022-03-25T17:29:27.826298Z","iopub.status.idle":"2022-03-25T17:29:27.887491Z","shell.execute_reply.started":"2022-03-25T17:29:27.826266Z","shell.execute_reply":"2022-03-25T17:29:27.886757Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"id2cat = list(data_category.values())\ncat2id = {v:k for k,v in enumerate(id2cat)}\nmcs = np.array([np.array([cat2id[p] for p in o]) for o in mc]); # all object labels 'id' per image, same as mc, but with id's not names\nmcs[:3]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:27.889446Z","iopub.execute_input":"2022-03-25T17:29:27.890050Z","iopub.status.idle":"2022-03-25T17:29:27.952238Z","shell.execute_reply.started":"2022-03-25T17:29:27.890012Z","shell.execute_reply":"2022-03-25T17:29:27.951481Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Do the same for bboxes\nmbb = [np.concatenate([p[0] for p in train_annotation[o]]) for o in data_ids]\nmbb[:3] # Each group of 4 is a bbox","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:27.953823Z","iopub.execute_input":"2022-03-25T17:29:27.954442Z","iopub.status.idle":"2022-03-25T17:29:28.016664Z","shell.execute_reply.started":"2022-03-25T17:29:27.954405Z","shell.execute_reply":"2022-03-25T17:29:28.015986Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"mbbs = [' '.join(str(p) for p in o) for o in mbb]\nmbbs[:3]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.018121Z","iopub.execute_input":"2022-03-25T17:29:28.018558Z","iopub.status.idle":"2022-03-25T17:29:28.097403Z","shell.execute_reply.started":"2022-03-25T17:29:28.018521Z","shell.execute_reply":"2022-03-25T17:29:28.096682Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'filename': [data_filename[o] for o in data_ids], 'bbox': mbbs, 'class':mcs}, columns=['filename','bbox','class'])","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.098863Z","iopub.execute_input":"2022-03-25T17:29:28.099367Z","iopub.status.idle":"2022-03-25T17:29:28.156954Z","shell.execute_reply.started":"2022-03-25T17:29:28.099331Z","shell.execute_reply":"2022-03-25T17:29:28.156130Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.158524Z","iopub.execute_input":"2022-03-25T17:29:28.158802Z","iopub.status.idle":"2022-03-25T17:29:28.225176Z","shell.execute_reply.started":"2022-03-25T17:29:28.158767Z","shell.execute_reply":"2022-03-25T17:29:28.224522Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def Split_Train_Valid(df,Split_train_val=0.7):\n    # step 1: shuffle the data\n    df = df.reindex(np.random.permutation(df.index))\n    df=df.set_index(np.arange(len(df)))\n    \n    # step 2: split in training and testing\n    df_train = df[:int(len(df)*Split_train_val)]\n    df_valid = df[int(len(df)*Split_train_val):]\n    df_train=df_train.set_index(np.arange(len(df_train)))\n    df_valid=df_valid.set_index(np.arange(len(df_valid)))\n    \n    return df_train,df_valid\n\ndf_train, df_valid = Split_Train_Valid(df,0.7)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.226861Z","iopub.execute_input":"2022-03-25T17:29:28.227121Z","iopub.status.idle":"2022-03-25T17:29:28.283899Z","shell.execute_reply.started":"2022-03-25T17:29:28.227088Z","shell.execute_reply":"2022-03-25T17:29:28.283124Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nclass Generator_MultiObject(Sequence):\n    'Generates data from a Dataframe'\n    def __init__(self, df, folder,preprocess_fct,batch_size=32, dim=(32,32), shuffle=True):\n        'Initialization'\n        self.preprocess_fct = preprocess_fct\n        self.dim = dim\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.folder = folder\n\n        self.df = df\n        self.n = len(df)            \n        self.nb_iteration = int(np.floor(self.n  / self.batch_size))\n        \n        self.on_epoch_end()\n                    \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return self.nb_iteration\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Generate data\n        X, y = self.__data_generation(indexes)\n\n        return X, y\n   \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, index):       \n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization \n        nb_label_max = 20\n        X = np.empty((self.batch_size, *self.dim, 3))\n        Y = []\n        # Generate data\n        for i, ID in enumerate(index):\n            # Read the image\n            img = Image.open(self.folder/self.df['filename'][ID])\n            \n            # extract the number of label\n            c = self.df['class'][ID]\n            nb_label = len(c)\n\n            # Class in a form of a one hot encoding\n            y = np.zeros((nb_label_max,1+4))\n            y[:nb_label,0] = c\n\n            # reshape the bounding box and resize\n            bbox = np.asmatrix(self.df['bbox'][ID])\n            bbox = bbox.reshape(nb_label,4)\n\n            bbox_rescaled = np.copy(bbox)\n            bbox_rescaled = bbox_rescaled.astype(float)\n            width, height = img.size\n            RatioX = width/self.dim[0]\n            RatioY = height/self.dim[1]\n\n            bbox_rescaled[:,0] = bbox_rescaled[:,0]/RatioY/self.dim[1]\n            bbox_rescaled[:,1] = bbox_rescaled[:,1]/RatioX/self.dim[0]\n            bbox_rescaled[:,2] = bbox_rescaled[:,2]/RatioY/self.dim[1]\n            bbox_rescaled[:,3] = bbox_rescaled[:,3]/RatioX/self.dim[0]\n\n            # save the bb coordinates\n            y[:nb_label,1:5] = bbox_rescaled\n\n\n            # reshape to a vector\n            y = np.reshape(y,nb_label_max*5) #whats this ???????????\n            img = np.asarray(img.resize(self.dim))\n            X[i,] = self.preprocess_fct(np.asarray(img))\n\n            Y.append(np.asarray(y))\n\n        Y = np.asarray(Y)\n        \n        return X, Y       ","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.285678Z","iopub.execute_input":"2022-03-25T17:29:28.285962Z","iopub.status.idle":"2022-03-25T17:29:28.350037Z","shell.execute_reply.started":"2022-03-25T17:29:28.285899Z","shell.execute_reply":"2022-03-25T17:29:28.349241Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_gen = Generator_MultiObject(df_train, IMG_PATH,preprocess_input,batch_size=32, dim=(sz,sz), shuffle=True)\nvalid_gen = Generator_MultiObject(df_valid, IMG_PATH,preprocess_input,batch_size=32, dim=(sz,sz), shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.351530Z","iopub.execute_input":"2022-03-25T17:29:28.351791Z","iopub.status.idle":"2022-03-25T17:29:28.405260Z","shell.execute_reply.started":"2022-03-25T17:29:28.351755Z","shell.execute_reply":"2022-03-25T17:29:28.404358Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"k=1\nanc_grid = 4\nanc_offset = 1/(anc_grid*2)\nanc_x = np.repeat(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\nanc_y = np.tile(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\n\nanc_ctrs = np.tile(np.stack([anc_x,anc_y],axis=1),(k,1))\nanc_sizes = np.array([[1/anc_grid,1/anc_grid] for i in range(anc_grid*anc_grid)])\nanchors = np.concatenate([anc_ctrs, anc_sizes], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.408686Z","iopub.execute_input":"2022-03-25T17:29:28.409254Z","iopub.status.idle":"2022-03-25T17:29:28.463412Z","shell.execute_reply.started":"2022-03-25T17:29:28.409224Z","shell.execute_reply":"2022-03-25T17:29:28.462620Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(anchors)#4x4=16","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.464691Z","iopub.execute_input":"2022-03-25T17:29:28.465009Z","iopub.status.idle":"2022-03-25T17:29:28.518463Z","shell.execute_reply.started":"2022-03-25T17:29:28.464954Z","shell.execute_reply":"2022-03-25T17:29:28.517629Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def hw2corners(ctr, hw): return np.concatenate((ctr-hw/2, ctr+hw/2), axis=1)\n\nanchor_corner = hw2corners(anchors[:,:2], anchors[:,2:])\nanchor_corner","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.519725Z","iopub.execute_input":"2022-03-25T17:29:28.520333Z","iopub.status.idle":"2022-03-25T17:29:28.574760Z","shell.execute_reply.started":"2022-03-25T17:29:28.520294Z","shell.execute_reply":"2022-03-25T17:29:28.574083Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"grid_sizes = 1/anc_grid\ngrid_sizes","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.576182Z","iopub.execute_input":"2022-03-25T17:29:28.576612Z","iopub.status.idle":"2022-03-25T17:29:28.631027Z","shell.execute_reply.started":"2022-03-25T17:29:28.576573Z","shell.execute_reply":"2022-03-25T17:29:28.630230Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def deprocess_img(processed_img):\n  x = processed_img.copy()\n  if len(x.shape) == 4:\n    x = np.squeeze(x, 0)\n  assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n                             \"dimension [1, height, width, channel] or [height, width, channel]\")\n  if len(x.shape) != 3:\n    raise ValueError(\"Invalid input to deprocessing image\")\n  \n  # perform the inverse of the preprocessiing step\n  x[:, :, 0] += 103.939\n  x[:, :, 1] += 116.779\n  x[:, :, 2] += 123.68\n  x = x[:, :, ::-1]\n\n  x = np.clip(x, 0, 255).astype('uint8')\n  return x","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.632524Z","iopub.execute_input":"2022-03-25T17:29:28.633313Z","iopub.status.idle":"2022-03-25T17:29:28.686492Z","shell.execute_reply.started":"2022-03-25T17:29:28.633271Z","shell.execute_reply":"2022-03-25T17:29:28.685582Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def show_ground_truth(ax, im, bbox, clas=None, prs=None, thresh=0.3):\n    bb = [bb_hw(o) for o in bbox]\n    if prs is None:  prs  = [None]*len(bb)\n    if clas is None: clas = [None]*len(bb)\n    ax = show_img(im, ax=ax)\n    for i,(b,c,pr) in enumerate(zip(bb, clas, prs)):\n        if((b[2]>1) and (pr is None or pr > thresh)):\n            draw_rect(ax, bb[i])\n            txt = f'{i}: '\n            if c is not None: txt += ('bg' if c==len(id2cat) else id2cat[c.astype(int)])\n            if pr is not None: txt += f' {pr:.2f}'\n            draw_text(ax, b[:2], txt) ","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.689454Z","iopub.execute_input":"2022-03-25T17:29:28.689850Z","iopub.status.idle":"2022-03-25T17:29:28.743216Z","shell.execute_reply.started":"2022-03-25T17:29:28.689813Z","shell.execute_reply":"2022-03-25T17:29:28.742467Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def get_y(y):\n    idx = np.where(y[:,3]-y[:,1]>0)\n    bbox = y[idx[0],1:5]\n    clas = y[idx[0],0]\n    clas=clas.astype('int')\n    return bbox,clas","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.744639Z","iopub.execute_input":"2022-03-25T17:29:28.745096Z","iopub.status.idle":"2022-03-25T17:29:28.797045Z","shell.execute_reply.started":"2022-03-25T17:29:28.745058Z","shell.execute_reply":"2022-03-25T17:29:28.796281Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Let’s now look at the ground truth y\nx,y = next(iter(train_gen))\n\n# pick-up an image\ni=8\nima = x[i]\nY = y[i].reshape(-1,5)\nbbox, clas= get_y(Y)\n\nfig, ax = plt.subplots(figsize=(7,7))\nshow_ground_truth(ax, deprocess_img(ima), bbox*sz, clas, None)# *224 since the coordinates are scaled 0..1","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:28.804865Z","iopub.execute_input":"2022-03-25T17:29:28.805366Z","iopub.status.idle":"2022-03-25T17:29:29.584899Z","shell.execute_reply.started":"2022-03-25T17:29:28.805337Z","shell.execute_reply":"2022-03-25T17:29:29.582474Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7,7))\nshow_ground_truth(ax, deprocess_img(ima), anchor_corner*224, None)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:29.585926Z","iopub.execute_input":"2022-03-25T17:29:29.586172Z","iopub.status.idle":"2022-03-25T17:29:30.022760Z","shell.execute_reply.started":"2022-03-25T17:29:29.586134Z","shell.execute_reply":"2022-03-25T17:29:30.022036Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"bbox","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.024154Z","iopub.execute_input":"2022-03-25T17:29:30.025183Z","iopub.status.idle":"2022-03-25T17:29:30.106294Z","shell.execute_reply.started":"2022-03-25T17:29:30.025025Z","shell.execute_reply":"2022-03-25T17:29:30.105227Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"bbox.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.111020Z","iopub.execute_input":"2022-03-25T17:29:30.111429Z","iopub.status.idle":"2022-03-25T17:29:30.206713Z","shell.execute_reply.started":"2022-03-25T17:29:30.111391Z","shell.execute_reply":"2022-03-25T17:29:30.205573Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"anchor_corner","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.211540Z","iopub.execute_input":"2022-03-25T17:29:30.211820Z","iopub.status.idle":"2022-03-25T17:29:30.293247Z","shell.execute_reply.started":"2022-03-25T17:29:30.211786Z","shell.execute_reply":"2022-03-25T17:29:30.291499Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"anchor_corner.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.297749Z","iopub.execute_input":"2022-03-25T17:29:30.299684Z","iopub.status.idle":"2022-03-25T17:29:30.375726Z","shell.execute_reply.started":"2022-03-25T17:29:30.299645Z","shell.execute_reply":"2022-03-25T17:29:30.375036Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"bbox[:,2:]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.380162Z","iopub.execute_input":"2022-03-25T17:29:30.382053Z","iopub.status.idle":"2022-03-25T17:29:30.463128Z","shell.execute_reply.started":"2022-03-25T17:29:30.382013Z","shell.execute_reply":"2022-03-25T17:29:30.462427Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"max_xy = np.minimum(bbox[:,None,2:],anchor_corner[:,2:])\nprint(max_xy.shape)\nmax_xy","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.464275Z","iopub.execute_input":"2022-03-25T17:29:30.464518Z","iopub.status.idle":"2022-03-25T17:29:30.527113Z","shell.execute_reply.started":"2022-03-25T17:29:30.464484Z","shell.execute_reply":"2022-03-25T17:29:30.526320Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"bbox[:,None,2:].shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.528478Z","iopub.execute_input":"2022-03-25T17:29:30.529242Z","iopub.status.idle":"2022-03-25T17:29:30.582565Z","shell.execute_reply.started":"2022-03-25T17:29:30.529203Z","shell.execute_reply":"2022-03-25T17:29:30.581888Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"anchor_corner[:, 2:].shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.584428Z","iopub.execute_input":"2022-03-25T17:29:30.584631Z","iopub.status.idle":"2022-03-25T17:29:30.639908Z","shell.execute_reply.started":"2022-03-25T17:29:30.584606Z","shell.execute_reply":"2022-03-25T17:29:30.639236Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"max_xy = np.minimum(bbox[:,None,2:], anchor_corner[:, 2:])\nmin_xy = np.maximum(bbox[:,None,:2], anchor_corner[:, :2])","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.641338Z","iopub.execute_input":"2022-03-25T17:29:30.641585Z","iopub.status.idle":"2022-03-25T17:29:30.693010Z","shell.execute_reply.started":"2022-03-25T17:29:30.641549Z","shell.execute_reply":"2022-03-25T17:29:30.692259Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"min_xy.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.694396Z","iopub.execute_input":"2022-03-25T17:29:30.694664Z","iopub.status.idle":"2022-03-25T17:29:30.747499Z","shell.execute_reply.started":"2022-03-25T17:29:30.694628Z","shell.execute_reply":"2022-03-25T17:29:30.746676Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"max_xy.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.749000Z","iopub.execute_input":"2022-03-25T17:29:30.749302Z","iopub.status.idle":"2022-03-25T17:29:30.802020Z","shell.execute_reply.started":"2022-03-25T17:29:30.749265Z","shell.execute_reply":"2022-03-25T17:29:30.801285Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"inter = np.clip((max_xy - min_xy),0,None)\n#inter = max_xy - min_xy # If no overlap, then the min_xy > max_xy, so -ve values. In this case the score = 0, as no overlap\ninter","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.803669Z","iopub.execute_input":"2022-03-25T17:29:30.804145Z","iopub.status.idle":"2022-03-25T17:29:30.862007Z","shell.execute_reply.started":"2022-03-25T17:29:30.804107Z","shell.execute_reply":"2022-03-25T17:29:30.861269Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"inter_scores = inter[:, :, 0] * inter[:, :, 1]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.863452Z","iopub.execute_input":"2022-03-25T17:29:30.864351Z","iopub.status.idle":"2022-03-25T17:29:30.914723Z","shell.execute_reply.started":"2022-03-25T17:29:30.864314Z","shell.execute_reply":"2022-03-25T17:29:30.913990Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"inter_scores.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.916115Z","iopub.execute_input":"2022-03-25T17:29:30.916695Z","iopub.status.idle":"2022-03-25T17:29:30.970746Z","shell.execute_reply.started":"2022-03-25T17:29:30.916657Z","shell.execute_reply":"2022-03-25T17:29:30.970014Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def box_sz(b): return ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))#area\n\ndef intersect(box_a, box_b):\n    \n    max_xy = np.minimum(box_a[:,None,2:], box_b[:, 2:])\n    min_xy = np.maximum(box_a[:,None,:2], box_b[:, :2])\n    \n    inter = np.clip((max_xy - min_xy),0,None)\n    return inter[:, :, 0] * inter[:, :, 1]\n\ndef jaccard(box_a, box_b): # this is the fancy name of IoU!\n    inter = intersect(box_a, box_b) \n    union = np.expand_dims(box_sz(box_a),1)+ np.expand_dims(box_sz(box_b),0) - inter  \n    \n    return inter/union","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:30.972254Z","iopub.execute_input":"2022-03-25T17:29:30.972683Z","iopub.status.idle":"2022-03-25T17:29:31.026628Z","shell.execute_reply.started":"2022-03-25T17:29:30.972601Z","shell.execute_reply":"2022-03-25T17:29:31.025883Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"overlaps = jaccard(bbox,anchor_corner)\noverlaps","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.028259Z","iopub.execute_input":"2022-03-25T17:29:31.028499Z","iopub.status.idle":"2022-03-25T17:29:31.083871Z","shell.execute_reply.started":"2022-03-25T17:29:31.028466Z","shell.execute_reply":"2022-03-25T17:29:31.083149Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"overlaps.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.087101Z","iopub.execute_input":"2022-03-25T17:29:31.087373Z","iopub.status.idle":"2022-03-25T17:29:31.141033Z","shell.execute_reply.started":"2022-03-25T17:29:31.087334Z","shell.execute_reply":"2022-03-25T17:29:31.139851Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"MaxOverlap = np.amax(overlaps,axis=1)\nID_Overlap_Anchor = np.argmax(overlaps,axis=1)\n \nprint('Max overlapp: ',MaxOverlap)\nprint('ID of anchors: ',ID_Overlap_Anchor)\n \nfig, ax = plt.subplots(figsize=(7,7))\nshow_ground_truth(ax, deprocess_img(ima), anchor_corner[ID_Overlap_Anchor,:]*224, clas, MaxOverlap,0)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.142773Z","iopub.execute_input":"2022-03-25T17:29:31.143240Z","iopub.status.idle":"2022-03-25T17:29:31.543756Z","shell.execute_reply.started":"2022-03-25T17:29:31.143197Z","shell.execute_reply":"2022-03-25T17:29:31.543114Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"MaxOverlap = np.amax(overlaps,axis=0)\nID_Overlap_GT = np.argmax(overlaps,axis=0)\n\nprint('Max overlapp: ',MaxOverlap)\nprint('ID of GT: ',ID_Overlap_GT)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.545023Z","iopub.execute_input":"2022-03-25T17:29:31.545524Z","iopub.status.idle":"2022-03-25T17:29:31.602657Z","shell.execute_reply.started":"2022-03-25T17:29:31.545487Z","shell.execute_reply":"2022-03-25T17:29:31.601899Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def map_to_ground_truth(overlaps, print_it=False):\n    \n    # for each GT, ID of the cell for which overlapp is maximum\n    prior_overlap = np.amax(overlaps,1)\n    prior_idx = np.argmax(overlaps,1) \n    \n    # for each cell, ID of the GT with the best overlapp \n    gt_overlap = np.amax(overlaps,0)\n    gt_idx = np.argmax(overlaps,0)\n        \n    # to ensure each GT matches with an anchor, whatever is the overlapp, meaning even low, \n    # we overwrite the overlapp with a constant value\n    gt_overlap[prior_idx] = 1.99 \n    for i,o in enumerate(prior_idx): gt_idx[o] = i\n    return gt_overlap,gt_idx","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.604910Z","iopub.execute_input":"2022-03-25T17:29:31.605623Z","iopub.status.idle":"2022-03-25T17:29:31.661247Z","shell.execute_reply.started":"2022-03-25T17:29:31.605495Z","shell.execute_reply":"2022-03-25T17:29:31.660382Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"gt_overlap,gt_idx = map_to_ground_truth(overlaps)\n\nprint(gt_overlap)\nprint(gt_idx)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.662647Z","iopub.execute_input":"2022-03-25T17:29:31.663017Z","iopub.status.idle":"2022-03-25T17:29:31.720135Z","shell.execute_reply.started":"2022-03-25T17:29:31.662963Z","shell.execute_reply":"2022-03-25T17:29:31.719325Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"clas","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.721590Z","iopub.execute_input":"2022-03-25T17:29:31.722331Z","iopub.status.idle":"2022-03-25T17:29:31.779141Z","shell.execute_reply.started":"2022-03-25T17:29:31.722245Z","shell.execute_reply":"2022-03-25T17:29:31.778250Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"gt_clas = clas[gt_idx]; \n\nprint(gt_clas)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.781196Z","iopub.execute_input":"2022-03-25T17:29:31.781747Z","iopub.status.idle":"2022-03-25T17:29:31.835695Z","shell.execute_reply.started":"2022-03-25T17:29:31.781708Z","shell.execute_reply":"2022-03-25T17:29:31.834493Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"thresh = 0.5\npos = gt_overlap > thresh\nprint(pos)\npos_idx = np.nonzero(pos)\nneg_idx = np.nonzero(1-pos)\npos_idx","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.837525Z","iopub.execute_input":"2022-03-25T17:29:31.838010Z","iopub.status.idle":"2022-03-25T17:29:31.894275Z","shell.execute_reply.started":"2022-03-25T17:29:31.837951Z","shell.execute_reply":"2022-03-25T17:29:31.893541Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"gt_clas[neg_idx] = len(id2cat)\n[id2cat[o] if o<len(id2cat) else 'bg' for o in gt_clas]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.895665Z","iopub.execute_input":"2022-03-25T17:29:31.896132Z","iopub.status.idle":"2022-03-25T17:29:31.950529Z","shell.execute_reply.started":"2022-03-25T17:29:31.896071Z","shell.execute_reply":"2022-03-25T17:29:31.949700Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def actn_to_bb(actn, anchors):# The bboxes are relative to 0,0. This function makes it relative to the center it's corresponding anchor center. We use tanh as the bbox will be centered arount the center of the anchor, so -ve values are allowed. That's why we divide by 2 also.\n    actn_bbs = np.tanh(actn)\n    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]  \n    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n    return hw2corners(actn_centers, actn_hw)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:31.951869Z","iopub.execute_input":"2022-03-25T17:29:31.952354Z","iopub.status.idle":"2022-03-25T17:29:32.005465Z","shell.execute_reply.started":"2022-03-25T17:29:31.952310Z","shell.execute_reply":"2022-03-25T17:29:32.004721Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"np.random.randint(0,224,(16,4))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:32.006879Z","iopub.execute_input":"2022-03-25T17:29:32.007453Z","iopub.status.idle":"2022-03-25T17:29:32.060584Z","shell.execute_reply.started":"2022-03-25T17:29:32.007376Z","shell.execute_reply":"2022-03-25T17:29:32.059799Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# we generate a random activation: 16*4\nb_bbox = np.random.randint(0,224,(16,4));\nb_bbox[:,2:] = b_bbox[:,2:] + b_bbox[:,:2]\nb_bbox[:,2:] = np.clip(b_bbox[:,2:],0,224)\nb_bbox = b_bbox / 224\n\na_ic = actn_to_bb(b_bbox, anchors)\n\nfig, ax = plt.subplots(figsize=(7,7))\nshow_ground_truth(ax, deprocess_img(ima), a_ic*224, None, None)# Note the scaling, as the outputs are 0..1","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:32.061872Z","iopub.execute_input":"2022-03-25T17:29:32.062324Z","iopub.status.idle":"2022-03-25T17:29:32.468366Z","shell.execute_reply.started":"2022-03-25T17:29:32.062286Z","shell.execute_reply":"2022-03-25T17:29:32.466627Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"b_bbox.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:32.469638Z","iopub.execute_input":"2022-03-25T17:29:32.472143Z","iopub.status.idle":"2022-03-25T17:29:32.526831Z","shell.execute_reply.started":"2022-03-25T17:29:32.472104Z","shell.execute_reply":"2022-03-25T17:29:32.526079Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# First, load our data\nx_batch,y_batch = next(iter(train_gen))\n\n# then, make a prediction\ny_pred = net.predict_on_batch(x_batch)\n\n# for the next step, let consider only one sample from the batch\nid_sample = 2\nX = x_batch[id_sample]\ny_GT = y_batch[id_sample]\ny_pred = y_pred[id_sample]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:32.529907Z","iopub.execute_input":"2022-03-25T17:29:32.530141Z","iopub.status.idle":"2022-03-25T17:29:42.208201Z","shell.execute_reply.started":"2022-03-25T17:29:32.530114Z","shell.execute_reply":"2022-03-25T17:29:42.207413Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# GT: the vector size is 20*(1+4) = 100, where we have [num class, 4 box coordinates] *20\nprint('GT shape',y_GT.shape)\n\ny_GT = y_GT.reshape(-1,5)\ngt_box,gt_clas = get_y(y_GT)\n\nprint('GT Box shape',gt_box.shape)\nprint('GT Class shape',gt_clas.shape)\n\n# The prediction: the tensor size is [16*20 +  16*4], where 16 is the number of activation, and then we have \n# a one hot vector class and 4 box coordinates\nprint('Prediction tensor shape',y_pred.shape)\npred_clas = np.reshape(y_pred[:16*20],(16,20))\npred_box = np.reshape(y_pred[16*20:],(16,4))\nprint('Prediction clas shape',pred_clas.shape)\nprint('Prediction box shape',pred_box.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.209806Z","iopub.execute_input":"2022-03-25T17:29:42.210210Z","iopub.status.idle":"2022-03-25T17:29:42.267749Z","shell.execute_reply.started":"2022-03-25T17:29:42.210174Z","shell.execute_reply":"2022-03-25T17:29:42.266911Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"a_ic = actn_to_bb(pred_box, anchors)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.270007Z","iopub.execute_input":"2022-03-25T17:29:42.270527Z","iopub.status.idle":"2022-03-25T17:29:42.322088Z","shell.execute_reply.started":"2022-03-25T17:29:42.270489Z","shell.execute_reply":"2022-03-25T17:29:42.321363Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# just have a look to the data\nplt.figure(1,figsize=(16, 12))\nax1=plt.subplot(2, 2, 1)\nax1.set_title('GT')\nshow_ground_truth(ax1, deprocess_img(X), gt_box*224)\nax2=plt.subplot(2, 2, 2)\nax2.set_title('Prediction')\nshow_ground_truth(ax2, deprocess_img(X), np.clip(pred_box,0,1)*224)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.323106Z","iopub.execute_input":"2022-03-25T17:29:42.323307Z","iopub.status.idle":"2022-03-25T17:29:42.705586Z","shell.execute_reply.started":"2022-03-25T17:29:42.323283Z","shell.execute_reply":"2022-03-25T17:29:42.704916Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"b_bbox.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.706807Z","iopub.execute_input":"2022-03-25T17:29:42.707168Z","iopub.status.idle":"2022-03-25T17:29:42.761752Z","shell.execute_reply.started":"2022-03-25T17:29:42.707137Z","shell.execute_reply":"2022-03-25T17:29:42.761038Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"overlaps = jaccard(gt_box, anchor_corner)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.763090Z","iopub.execute_input":"2022-03-25T17:29:42.763359Z","iopub.status.idle":"2022-03-25T17:29:42.815229Z","shell.execute_reply.started":"2022-03-25T17:29:42.763324Z","shell.execute_reply":"2022-03-25T17:29:42.814468Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# it returns for each cell the best overlapp with the GT and the GT id\ngt_overlap,gt_idx = map_to_ground_truth(overlaps,0) \nsel_gt_clas = gt_clas[gt_idx]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.817497Z","iopub.execute_input":"2022-03-25T17:29:42.818009Z","iopub.status.idle":"2022-03-25T17:29:42.870245Z","shell.execute_reply.started":"2022-03-25T17:29:42.817953Z","shell.execute_reply":"2022-03-25T17:29:42.869324Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"sel_gt_clas","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.871662Z","iopub.execute_input":"2022-03-25T17:29:42.871927Z","iopub.status.idle":"2022-03-25T17:29:42.925811Z","shell.execute_reply.started":"2022-03-25T17:29:42.871890Z","shell.execute_reply":"2022-03-25T17:29:42.924581Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"pos = gt_overlap > 0.4\npos_idx = np.nonzero(pos)[0]# idx of anchors\nneg_idx = np.nonzero(1-pos)[0]\n# we keep neg_idx for a next step, where it will be used to tell to our Loss that there is \n# nothing in that cell to consider, meaning it a a background cell\n\nsel_gt_bbox = gt_box[gt_idx]","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.927122Z","iopub.execute_input":"2022-03-25T17:29:42.927482Z","iopub.status.idle":"2022-03-25T17:29:42.981982Z","shell.execute_reply.started":"2022-03-25T17:29:42.927444Z","shell.execute_reply":"2022-03-25T17:29:42.980924Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"gt_idx#assignation of each of the 16 anchors to the gt_box idx. In this case it's just 1 so all are index 0.","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:42.983325Z","iopub.execute_input":"2022-03-25T17:29:42.983779Z","iopub.status.idle":"2022-03-25T17:29:43.038355Z","shell.execute_reply.started":"2022-03-25T17:29:42.983741Z","shell.execute_reply":"2022-03-25T17:29:43.037613Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"gt_box.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.039569Z","iopub.execute_input":"2022-03-25T17:29:43.039758Z","iopub.status.idle":"2022-03-25T17:29:43.091619Z","shell.execute_reply.started":"2022-03-25T17:29:43.039735Z","shell.execute_reply":"2022-03-25T17:29:43.090869Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"gt_box[gt_idx].shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.093154Z","iopub.execute_input":"2022-03-25T17:29:43.093576Z","iopub.status.idle":"2022-03-25T17:29:43.146738Z","shell.execute_reply.started":"2022-03-25T17:29:43.093538Z","shell.execute_reply":"2022-03-25T17:29:43.146029Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"gt_overlap.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.148173Z","iopub.execute_input":"2022-03-25T17:29:43.148449Z","iopub.status.idle":"2022-03-25T17:29:43.202737Z","shell.execute_reply.started":"2022-03-25T17:29:43.148413Z","shell.execute_reply":"2022-03-25T17:29:43.201983Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"pos","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.204941Z","iopub.execute_input":"2022-03-25T17:29:43.205658Z","iopub.status.idle":"2022-03-25T17:29:43.259212Z","shell.execute_reply.started":"2022-03-25T17:29:43.205631Z","shell.execute_reply":"2022-03-25T17:29:43.258324Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"pos_idx","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.261059Z","iopub.execute_input":"2022-03-25T17:29:43.261484Z","iopub.status.idle":"2022-03-25T17:29:43.313767Z","shell.execute_reply.started":"2022-03-25T17:29:43.261447Z","shell.execute_reply":"2022-03-25T17:29:43.313082Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"sel_gt_bbox.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.314886Z","iopub.execute_input":"2022-03-25T17:29:43.315339Z","iopub.status.idle":"2022-03-25T17:29:43.369551Z","shell.execute_reply.started":"2022-03-25T17:29:43.315301Z","shell.execute_reply":"2022-03-25T17:29:43.368778Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"sel_gt_bbox","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.371041Z","iopub.execute_input":"2022-03-25T17:29:43.371618Z","iopub.status.idle":"2022-03-25T17:29:43.426701Z","shell.execute_reply.started":"2022-03-25T17:29:43.371578Z","shell.execute_reply":"2022-03-25T17:29:43.426024Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"loc_loss = np.mean(np.sum(np.abs(a_ic[pos_idx] - sel_gt_bbox[pos_idx]),axis=1))\nprint('Localization loss is: ',loc_loss)\nprint('It means an average error in pixel of: ',loc_loss*224)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.428872Z","iopub.execute_input":"2022-03-25T17:29:43.429868Z","iopub.status.idle":"2022-03-25T17:29:43.482924Z","shell.execute_reply.started":"2022-03-25T17:29:43.429830Z","shell.execute_reply":"2022-03-25T17:29:43.482119Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# just have a look to the data\nplt.figure(1,figsize=(16, 12))\nax1=plt.subplot(2, 2, 1)\nax1.set_title('GT')\nshow_ground_truth(ax1, deprocess_img(X), sel_gt_bbox[pos_idx]*224)\nax1=plt.subplot(2, 2, 2)\nax1.set_title('Pred')\nshow_ground_truth(ax1, deprocess_img(X), a_ic[pos_idx]*224)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.484432Z","iopub.execute_input":"2022-03-25T17:29:43.485681Z","iopub.status.idle":"2022-03-25T17:29:43.857403Z","shell.execute_reply.started":"2022-03-25T17:29:43.485640Z","shell.execute_reply":"2022-03-25T17:29:43.855637Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"overlaps","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.858699Z","iopub.execute_input":"2022-03-25T17:29:43.859100Z","iopub.status.idle":"2022-03-25T17:29:43.915446Z","shell.execute_reply.started":"2022-03-25T17:29:43.859064Z","shell.execute_reply":"2022-03-25T17:29:43.914677Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# The gt_box is:\ngt_box*224 # not that it's normalized","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.916772Z","iopub.execute_input":"2022-03-25T17:29:43.917161Z","iopub.status.idle":"2022-03-25T17:29:43.972348Z","shell.execute_reply.started":"2022-03-25T17:29:43.917121Z","shell.execute_reply":"2022-03-25T17:29:43.971608Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# we will use the Binary Cross Entropy as we did in the previous lesson\n# pos_idx is the id of anchor box, all the rest should ba at zero because it does not contain any box\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nlabel = keras.utils.np_utils.to_categorical(sel_gt_clas, 20)# 20 here is the number of classes\nlabel[neg_idx,:]=0\n\nclas_loss = K.eval(K.mean(K.binary_crossentropy(K.cast(label,\"float64\"), K.cast(pred_clas,\"float64\"))))\n\nprint(\"Binary Cross Entropy loss = \",clas_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:43.973774Z","iopub.execute_input":"2022-03-25T17:29:43.974567Z","iopub.status.idle":"2022-03-25T17:29:44.050919Z","shell.execute_reply.started":"2022-03-25T17:29:43.974527Z","shell.execute_reply":"2022-03-25T17:29:44.050222Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# there is a scale difference between classification Loss (around 4) and localization Loss (around 0.4). \n# So, we put a weight of 10 on the localization Loss\nLoss = clas_loss + loc_loss*10\nprint(\"The Global Loss is = \",Loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:44.053772Z","iopub.execute_input":"2022-03-25T17:29:44.054138Z","iopub.status.idle":"2022-03-25T17:29:44.106291Z","shell.execute_reply.started":"2022-03-25T17:29:44.054103Z","shell.execute_reply":"2022-03-25T17:29:44.105355Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.utils import np_utils\n\ndef SSD_Loss_1(y_GT,y_pred):\n    \n    # Step 1: we split the tensor into box and class for both GT and prediction\n    y_GT = y_GT.reshape(-1,5)\n    \n    gt_box,gt_clas =  get_y(y_GT)\n\n    pred_clas = y_pred[:20*16]\n    pred_box = y_pred[20*16:]\n    pred_clas = pred_clas.reshape(-1,20)\n    pred_box = pred_box.reshape(-1,4)\n\n    # step 2: we convert activation into box\n    a_ic = actn_to_bb(pred_box, anchors)\n        \n    # step 3: we estimate the overlapp between the activation and the anchor\n    overlaps = jaccard(gt_box, anchor_corner)\n    \n    # step 4: we map with the GT\n    prior_overlap = np.amax(overlaps,1) # [20] for each GT, value of tye best overlapp\n    prior_idx = np.argmax(overlaps,1) # [20] for each GT, ID of best anchors   \n    gt_overlap = np.amax(overlaps,0) # [16] for each cell, ID of the GT with the best overlapp \n    gt_idx = np.argmax(overlaps,0) # [16] for each activation, ID of the GT with the best overlapp   \n            \n    # We ensure that for each gt box, we select an activation\n    gt_overlap[prior_idx] = 1.99\n    for i,o in enumerate(prior_idx): gt_idx[o] = i\n    \n    sel_gt_clas = gt_clas[gt_idx]\n\n    # setp 5: We threshold the overlapp to keep only \"active\" anchors\n    pos = gt_overlap > 0.4\n    pos_idx = np.nonzero(pos)[0]\n    neg_idx = np.nonzero(1-pos)[0]\n    sel_gt_bbox = gt_box[gt_idx]\n   \n    # step 6: localization Loss   \n    loc_loss = np.mean(np.sum(np.abs(a_ic[pos_idx] - sel_gt_bbox[pos_idx]),axis=1))\n    \n    # step 7: Classification Loss\n    # we will use the Binary Cross Entropy as we did in the previous lesson\n    # pos_idx is the id of anchor box, all the rest shoudl ba at zero because it does not contain any box\n    label = keras.utils.np_utils.to_categorical(sel_gt_clas, 20)\n    label[neg_idx,:]=0\n\n    clas_loss = K.eval(K.mean(K.binary_crossentropy(label, pred_clas)))\n\n    \n    print('localization Loss:',loc_loss)\n    print('classification loss:',clas_loss)\n    return clas_loss + 10*loc_loss\n\ndef SSD_Loss(y_batch,y_pred):\n    loss = 0\n    for y_b,y_p in zip(y_batch,y_pred):\n        loss += SSD_Loss_1(y_b,y_p)\n    \n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:44.113914Z","iopub.execute_input":"2022-03-25T17:29:44.114281Z","iopub.status.idle":"2022-03-25T17:29:44.175239Z","shell.execute_reply.started":"2022-03-25T17:29:44.114250Z","shell.execute_reply":"2022-03-25T17:29:44.174360Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"SSD_Loss(np.expand_dims(y_GT,0),np.expand_dims(y_pred,0))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:44.176417Z","iopub.execute_input":"2022-03-25T17:29:44.176713Z","iopub.status.idle":"2022-03-25T17:29:44.241037Z","shell.execute_reply.started":"2022-03-25T17:29:44.176671Z","shell.execute_reply":"2022-03-25T17:29:44.240232Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"loss = SSD_Loss(np.expand_dims(y_GT,0),np.expand_dims(y_pred,0))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T17:29:44.242531Z","iopub.execute_input":"2022-03-25T17:29:44.242801Z","iopub.status.idle":"2022-03-25T17:29:44.299148Z","shell.execute_reply.started":"2022-03-25T17:29:44.242767Z","shell.execute_reply":"2022-03-25T17:29:44.298226Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}